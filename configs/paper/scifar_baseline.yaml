# sCIFAR Baseline Configuration for Paper Reproduction
# Paper Table 3: Baseline (no reduction)
# Expected accuracy: ~86.5Â±0.3%

# Dataset
dataset: scifar

# Model Architecture (Paper Table 1)
model:
  num_blocks: 6           # Number of LRU blocks
  state_dim: 384          # State dimension per block (N)
  hidden_dim: 512         # Hidden dimension (H)
  r_min: 0.9              # Minimum eigenvalue magnitude
  r_max: 0.999            # Maximum eigenvalue magnitude
  drop_rate: 0.1          # Dropout rate (Paper Table 1)

# Training Hyperparameters (Paper Table 1)
training:
  num_steps: 180000       # Total training steps
  batch_size: 50          # Batch size
  lr: 0.001               # Base learning rate
  weight_decay: 0.05      # AdamW weight decay
  ssm_lr_factor: 0.25     # LR multiplier for SSM params
  use_warmup_cosine: true # Use warmup + cosine annealing schedule
  eval_steps: 4500        # Evaluation frequency

# Reduction Configuration
reduction:
  mode: none              # Baseline: no reduction
  selection: largest
  tol: 0.95
  red_start: 0            # Not used for baseline
  red_end: 18000          # 10% of training (not used for baseline)
  red_interval: 2000
  hsv_interval: 0         # No HSV logging
  reduction_fraction: 0.1
  performance_tolerance: 0.02
  method: sqrtm
